import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset, WeightedRandomSampler
from torchvision import transforms
from torchvision.models.vision_transformer import vit_b_16
from PIL import Image
import os
import glob
from tqdm import tqdm
import numpy as np
import random
import pandas as pd
from sklearn.metrics import roc_auc_score
from sklearn.model_selection import train_test_split

# –ü—É—Ç–∏ –∫ –¥–∞–Ω–Ω—ã–º
PATHS = {
    "images_dir": "C:/Users/User/Desktop/IVF/AI/Blastocyst_Dataset/Images",
    "metadata": "C:/Users/User/Desktop/IVF/AI/Blastocyst_Dataset/Clincial_annotations.xlsx"
}

# –ö–ª–∞—Å—Å—ã –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å ViT
class CustomViTEncoder(nn.Module):
    def __init__(self, vit_model):
        super().__init__()
        self.vit = vit_model
        self.hidden_dim = vit_model.hidden_dim
        self.patch_size = vit_model.patch_size
        self.image_size = vit_model.image_size
        self.class_token = vit_model.class_token
        self.conv_proj = vit_model.conv_proj
        self.encoder = vit_model.encoder
        self.pos_embedding = vit_model.encoder.pos_embedding

    def forward(self, x):
        n, c, h, w = x.shape
        p = self.patch_size
        n_h = h // p
        n_w = w // p

        x = self.conv_proj(x)
        x = x.reshape(n, self.hidden_dim, n_h * n_w)
        x = x.permute(0, 2, 1)

        class_token = self.class_token.expand(n, -1, -1)
        x = torch.cat([class_token, x], dim=1)

        if self.pos_embedding is not None:
            x = x + self.pos_embedding

        x = self.encoder(x)
        return x

class ViTClassifier(nn.Module):
    def __init__(self, encoder, num_classes=2):
        super().__init__()
        self.encoder = encoder

        # –ó–∞–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —ç–Ω–∫–æ–¥–µ—Ä –Ω–∞ –Ω–∞—á–∞–ª—å–Ω—ã—Ö —ç—Ç–∞–ø–∞—Ö
        for param in self.encoder.parameters():
            param.requires_grad = False

        self.classifier = nn.Sequential(
            nn.Linear(768, 512),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(512, num_classes)
        )

    def forward(self, x):
        # –ü–æ–ª—É—á–∞–µ–º –≤—ã—Ö–æ–¥ —ç–Ω–∫–æ–¥–µ—Ä–∞ [batch_size, 197, 768]
        features = self.encoder(x)

        # –ë–µ—Ä–µ–º class token (–ø–µ—Ä–≤—ã–π —Ç–æ–∫–µ–Ω) –¥–ª—è –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        cls_token = features[:, 0, :]

        return self.classifier(cls_token)

    def unfreeze_encoder(self, last_n_layers=3):
        """–†–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å–ª–æ–∏ —ç–Ω–∫–æ–¥–µ—Ä–∞"""
        total_layers = len(self.encoder.encoder.layers)

        for i, layer in enumerate(self.encoder.encoder.layers):
            if i >= total_layers - last_n_layers:
                for param in layer.parameters():
                    param.requires_grad = True

# –ö–ª–∞—Å—Å –¥–∞—Ç–∞—Å–µ—Ç–∞ —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –º–µ—Ç–æ–∫ –≤ —Å–∞–º–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ
class EmbryoExcelDataset(Dataset):
    def __init__(self, images_dir, metadata_path, transform=None):
        """
        images_dir: –ø–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏
        metadata_path: –ø—É—Ç—å –∫ Excel-—Ñ–∞–π–ª—É —Å –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–º–∏
        """
        self.images_dir = images_dir
        self.transform = transform or transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor(),
        ])
        self.samples = []  # –ë—É–¥–µ—Ç —Ö—Ä–∞–Ω–∏—Ç—å –∫–æ—Ä—Ç–µ–∂–∏ (–ø—É—Ç—å_–∫_–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é, –º–µ—Ç–∫–∞)

        # –ó–∞–≥—Ä—É–∂–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∏–∑ Excel
        metadata = pd.read_excel(metadata_path)
        print(f"Loaded metadata with {len(metadata)} rows")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤
        if 'HA' not in metadata.columns:
            raise ValueError("Metadata does not contain 'HA' column")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Å—Ç–æ–ª–±–µ—Ü —Å –∏–º–µ–Ω–∞–º–∏ —Ñ–∞–π–ª–æ–≤
        image_col = None
        for col in ['Image', 'Filename', 'File', 'Image Name']:
            if col in metadata.columns:
                image_col = col
                break

        if image_col is None:
            raise ValueError("Metadata does not contain image filename column")

        print(f"Using '{image_col}' column for image filenames")

        # –°–æ–±–∏—Ä–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        all_images = []
        for ext in ['*.jpg', '*.jpeg', '*.png']:
            all_images.extend(glob.glob(os.path.join(images_dir, ext)))
        print(f"Found {len(all_images)} images in directory")

        # –°–æ–∑–¥–∞–µ–º —Å–ø–∏—Å–æ–∫ –æ–±—Ä–∞–∑—Ü–æ–≤
        for _, row in metadata.iterrows():
            filename = row[image_col]
            label = row['HA']

            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–≤–∞–ª–∏–¥–Ω—ã–µ –º–µ—Ç–∫–∏
            if pd.isna(label) or label not in [0, 1]:
                continue

            # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–µ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            found = False
            for img_path in all_images:
                img_filename = os.path.basename(img_path)

                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å –∏–º–µ–Ω–µ–º —Ñ–∞–π–ª–∞ –∏–ª–∏ –∏–º–µ–Ω–µ–º –±–µ–∑ —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
                if filename == img_filename or filename == os.path.splitext(img_filename)[0]:
                    self.samples.append((img_path, int(label)))
                    found = True
                    break

            if not found:
                print(f"Warning: Image not found for {filename}")

        print(f"Created dataset with {len(self.samples)} samples")

        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è
        self.labels = [label for _, label in self.samples]
        if self.labels:
            class_counts = np.bincount(self.labels)
            print(f"Class distribution: {class_counts}")

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        img_path, label = self.samples[idx]
        img = Image.open(img_path).convert("RGB")

        if self.transform:
            img = self.transform(img)

        return img, label

def train_classifier(model, train_loader, val_loader, device, train_labels, epochs=30, lr=1e-4):
    model.to(device)
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=1e-5)

    # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –≤–µ—Å–∞ –∫–ª–∞—Å—Å–æ–≤ –¥–ª—è –¥–∏—Å–±–∞–ª–∞–Ω—Å–∞
    if train_labels:
        class_counts = np.bincount(train_labels)
        class_weights = torch.tensor([
            len(train_labels) / (2 * class_counts[0]),
            len(train_labels) / (2 * class_counts[1])
        ], dtype=torch.float).to(device)
        criterion = nn.CrossEntropyLoss(weight=class_weights)
        print(f"Using class weights: {class_weights.cpu().numpy()}")
    else:
        criterion = nn.CrossEntropyLoss()

    best_val_auc = 0.0

    for epoch in range(epochs):
        # –¢—Ä–µ–Ω–∏—Ä–æ–≤–∫–∞
        model.train()
        train_loss = 0
        train_total = 0

        for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs} [Train]"):
            imgs, labels = imgs.to(device), labels.to(device)

            optimizer.zero_grad()
            logits = model(imgs)
            loss = criterion(logits, labels)
            loss.backward()
            optimizer.step()

            train_loss += loss.item()
            train_total += labels.size(0)

        # –í–∞–ª–∏–¥–∞—Ü–∏—è - —Å–æ–±–∏—Ä–∞–µ–º –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ AUC
        model.eval()
        val_loss = 0
        all_labels = []
        all_probs = []

        with torch.no_grad():
            for imgs, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{epochs} [Val]"):
                imgs, labels = imgs.to(device), labels.to(device)

                logits = model(imgs)
                loss = criterion(logits, labels)
                val_loss += loss.item()

                # –ü–æ–ª—É—á–∞–µ–º –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–ª–∞—Å—Å–∞ 1
                probs = torch.softmax(logits, dim=1)[:, 1]
                all_probs.extend(probs.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º AUC
        if len(np.unique(all_labels)) >= 2:
            val_auc = roc_auc_score(all_labels, all_probs)
        else:
            val_auc = 0.5  # –ï—Å–ª–∏ —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å –≤ –≤–∞–ª–∏–¥–∞—Ü–∏–∏

        # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º —Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
        predictions = [1 if p > 0.5 else 0 for p in all_probs]
        val_acc = np.mean(np.array(predictions) == np.array(all_labels))

        avg_train_loss = train_loss / len(train_loader)
        avg_val_loss = val_loss / len(val_loader)

        print(f"Epoch {epoch+1}/{epochs}:")
        print(f"  Train Loss: {avg_train_loss:.4f}")
        print(f"  Val Loss: {avg_val_loss:.4f} | AUC: {val_auc:.4f} | Acc: {val_acc:.4f}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ AUC
        if val_auc > best_val_auc:
            best_val_auc = val_auc
            torch.save(model.state_dict(), "MAE_vit_classifier.pth")
            print(f"  üèÜ New best model saved with val AUC: {val_auc:.4f}")

        # –ü–æ—Å–ª–µ 5 —ç–ø–æ—Ö —Ä–∞–∑–º–æ—Ä–∞–∂–∏–≤–∞–µ–º —á–∞—Å—Ç—å —ç–Ω–∫–æ–¥–µ—Ä–∞
        if epoch == 5:
            model.unfreeze_encoder(last_n_layers=3)
            print("  üîì Unfreezing last 3 encoder layers")

    print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")

def main():
    # –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

    # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç
    dataset = EmbryoExcelDataset(
        images_dir=PATHS["images_dir"],
        metadata_path=PATHS["metadata"],
        transform=transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.RandomCrop(224),
            transforms.RandomHorizontalFlip(),
            transforms.RandomRotation(10),
            transforms.ToTensor(),
        ])
    )

    # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –º–µ—Ç–∫–∏ –¥–ª—è —Å—Ç—Ä–∞—Ç–∏—Ñ–∏–∫–∞—Ü–∏–∏
    all_labels = [label for _, label in dataset]

    # –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val (80/20)
    train_indices, val_indices = train_test_split(
        list(range(len(dataset))),
        test_size=0.2,
        stratify=all_labels,
        random_state=42
    )

    # –°–æ–∑–¥–∞–µ–º –ø–æ–¥–º–Ω–æ–∂–µ—Å—Ç–≤–∞
    train_dataset = torch.utils.data.Subset(dataset, train_indices)
    val_dataset = torch.utils.data.Subset(dataset, val_indices)

    # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∫–∏ –¥–ª—è —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞
    train_labels = [all_labels[i] for i in train_indices]

    # –°–æ–∑–¥–∞–µ–º —Å—ç–º–ø–ª–µ—Ä –¥–ª—è –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏ –∫–ª–∞—Å—Å–æ–≤
    if train_labels:
        class_counts = np.bincount(train_labels)
        class_weights = 1.0 / class_counts
        sample_weights = [class_weights[label] for label in train_labels]

        train_sampler = WeightedRandomSampler(
            weights=sample_weights,
            num_samples=len(train_indices) * 2,  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –≤—ã–±–æ—Ä–∫—É
            replacement=True
        )
    else:
        train_sampler = None

    train_loader = DataLoader(
        train_dataset,
        batch_size=32,
        sampler=train_sampler,
        num_workers=4,
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=32,
        shuffle=False,
        num_workers=4,
        pin_memory=True
    )

    # –°–æ–∑–¥–∞–µ–º –∏ –∑–∞–≥—Ä—É–∂–∞–µ–º –º–æ–¥–µ–ª—å
    base_vit = vit_b_16(pretrained=False)
    base_vit.heads = nn.Identity()

    encoder = CustomViTEncoder(base_vit)

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—ã–µ –≤–µ—Å–∞ –∏–∑ MAE
    checkpoint = torch.load("mae_femi_best.pth", map_location=device)

    # –£–¥–∞–ª—è–µ–º –∫–ª—é—á–∏, —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –≥–æ–ª–æ–≤–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
    encoder_state_dict = {}
    for key, value in checkpoint["encoder"].items():
        if 'vit.heads.head' not in key:
            encoder_state_dict[key] = value

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–π state_dict
    missing_keys, unexpected_keys = encoder.load_state_dict(encoder_state_dict, strict=False)

    print(f"Missing keys: {missing_keys}")
    print(f"Unexpected keys: {unexpected_keys}")

    model = ViTClassifier(encoder=encoder, num_classes=2)

    # –û–±—É—á–∞–µ–º –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä, –ø–µ—Ä–µ–¥–∞–≤–∞—è –º–µ—Ç–∫–∏ —Ç—Ä–µ–Ω–∏—Ä–æ–≤–æ—á–Ω–æ–≥–æ –Ω–∞–±–æ—Ä–∞
    train_classifier(
        model,
        train_loader,
        val_loader,
        device,
        train_labels=train_labels,
        epochs=30,
        lr=1e-4
    )

if __name__ == "__main__":
    main()
